#!/usr/bin/env python
import argparse
import time
import random
import sys
from multiprocessing import Process, active_children
from subprocess import check_output
import os
current_script_dir = os.path.dirname(os.path.realpath(__file__)).replace('/bin', '/python')
if not os.path.exists(current_script_dir):
    print 'WARNING current script dir %s doesn\'t exist, so python path may not be correctly set' % current_script_dir
sys.path.insert(1, current_script_dir)

import utils
from partitiondriver import PartitionDriver

# ----------------------------------------------------------------------------------------
def default_parameter_dir(args):
    if args.seqfile is not None:
        label = os.path.basename(args.seqfile[ : args.seqfile.rfind('.')])
    else:
        label = 'no-need-for-a-name'
    pdir = '_output/' + label
    return pdir

# ----------------------------------------------------------------------------------------
def check_maybe_auto_cache_parameters(args, parter=None):
    auto_ran_cache_parameters = False
    if not os.path.exists(args.parameter_dir):
        print '  note: --parameter-dir \'%s\' does not exist, so proceeding to cache a new set of parameters' % args.parameter_dir
        if parter is None:
            parter = PartitionDriver(args)
        tmpaction = args.action
        args.action = 'cache-parameters'  # gets used inside of partitiondriver
        parter.cache_parameters()
        args.action = tmpaction
        auto_ran_cache_parameters = True
    return auto_ran_cache_parameters

# ----------------------------------------------------------------------------------------
def set_default_parameter_dir(args):
    used_default_parameter_dir = False
    if args.parameter_dir is None:
        args.parameter_dir = default_parameter_dir(args)
        print '  note: using default --parameter-dir \'%s\'' % args.parameter_dir
        used_default_parameter_dir = True
    return used_default_parameter_dir

# ----------------------------------------------------------------------------------------
def run_simulation(args):
    from recombinator import Recombinator

    if args.n_sim_events / args.n_procs > args.n_trees:
        raise Exception('requested more simulated events per process (%d / %d = %d) than trees (%d) (you should increase --n-trees, so the clonal families don\'t mostly have the same tree)' % (args.n_sim_events, args.n_procs, args.n_sim_events / args.n_procs, args.n_trees))  # doesn't really need to be an exception, but just for now...
    if args.outfname is None:
        raise Exception('have to specify --outfname for simulation')
    if not args.n_sim_events > 0:
        raise Exception('--n-sim-events has to be a positivie number')
    if args.slurm:
        raise Exception('simulator parallelization does not handle slurm')
    if args.seqfile is not None:
        print '  NOTE --seqfile is not used when simulating'
    if args.n_max_queries != -1:
        print '  NOTE --n-max-queries is not used when simulating (use --n-sim-events to set the simulated number of rearrangemt events)'

    def make_events(n_events, iproc, random_ints):
        assert n_events > 0
        # NOTE all the different seeds! this sucks but is necessary
        reco = Recombinator(args, seed=args.seed+iproc, sublabel=str(iproc))
        for ievt in range(n_events):
            # print ievt,
            # sys.stdout.flush()
            failed = True
            itry = 0
            while failed:
                if itry > 0:
                    print 'try again: %d' % itry
                failed = not reco.combine(random_ints[ievt] + itry)
                itry += 1

    print 'simulating'

    used_default_parameter_dir = set_default_parameter_dir(args)
    auto_ran_cache_parameters = check_maybe_auto_cache_parameters(args)

    if used_default_parameter_dir or auto_ran_cache_parameters:  # add the subdirectory, either 'sw' or 'hmm' (probably the latter)
        args.parameter_dir += '/' + args.parameter_type

    n_per_proc = int(float(args.n_sim_events) / args.n_procs)
    all_random_ints = []
    for iproc in range(args.n_procs):  # have to generate these all at once, 'cause each of the subprocesses is going to reset its seed and god knows what happens to our seed at that point
        all_random_ints.append([random.randint(0, sys.maxint) for i in range(n_per_proc)])
    for iproc in range(args.n_procs):
        proc = Process(target=make_events, args=(n_per_proc, iproc, all_random_ints[iproc]))
        proc.start()
    while len(active_children()) > 0:
        # print ' wait %s' % len(active_children()),
        sys.stdout.flush()
        time.sleep(1)
    utils.merge_csvs(args.outfname, [args.workdir + '/recombinator-' + str(iproc) + '/' + os.path.basename(args.outfname) for iproc in range(args.n_procs)], cleanup=(not args.no_clean))

# ----------------------------------------------------------------------------------------
def run_partitiondriver(args):
    args.queries = utils.get_arg_list(args.queries)
    args.reco_ids = utils.get_arg_list(args.reco_ids)
    args.n_max_per_region = utils.get_arg_list(args.n_max_per_region, intify=True)
    args.match_mismatch = utils.get_arg_list(args.match_mismatch, intify=True)
    args.annotation_clustering_thresholds = utils.get_arg_list(args.annotation_clustering_thresholds, floatify=True)
    args.naive_hamming_bounds = utils.get_arg_list(args.naive_hamming_bounds, floatify=True)
    if args.seed_unique_id is not None:
        args.seed_unique_id = args.seed_unique_id.strip()  # protect against the space you have to put in front of it if it's got an initial minus sign
    if args.sw_debug is None:  # if not explicitly set, set equal to regular debug
        args.sw_debug = args.debug
    if len(args.n_max_per_region) != 3:
        raise Exception('n-max-per-region should be of the form \'x:y:z\', but I got ' + str(args.n_max_per_region))
    if len(args.match_mismatch) != 2:
        raise Exception('match-mismatch should be of the form \'match:mismatch\', but I got ' + str(args.n_max_per_region))
    if args.seqfile is None:
        raise Exception('--seqfile is required for the \'%s\' action' % args.action)

    parter = PartitionDriver(args)

    used_default_parameter_dir = set_default_parameter_dir(args)

    if args.action == 'cache-parameters':
        parter.cache_parameters()
        return

    auto_ran_cache_parameters = check_maybe_auto_cache_parameters(args, parter)

    if used_default_parameter_dir or auto_ran_cache_parameters:  # add the subdirectory, either 'sw' or 'hmm' (probably the latter)
        args.parameter_dir += '/' + args.parameter_type

    if 'run-' in args.action:
        parter.run_algorithm(args.action.replace('run-', ''))
    elif args.action == 'partition':
        parter.partition()
    else:
        raise Exception('bad action ' + args.action)

    parter.clean()

# ----------------------------------------------------------------------------------------
def view_existing_output(args):
    if args.outfname is None:
        raise Exception('--outfname is required for action \'%s\'' % args.action)
    if not os.path.exists(args.outfname):
        raise Exception('--outfname \'%s\' does not exist' % args.outfname)

    parter = PartitionDriver(args)
    if args.action == 'view-annotations':
        parter.view_existing_annotations()
    elif args.action == 'view-partitions':
        parter.view_existing_partitions()
    else:
        assert False

# ----------------------------------------------------------------------------------------
if os.getenv('USER') is not None and 'ralph' in os.getenv('USER'):
    print '    TODO make things completely assertion/exception safe, i.e. if you catch one, that causes a failure on that one sequence only'
    print '    TODO see about varying the naive hfrac thresholds -- especially lowering the lower bound (try to do this by exploiting something about the difference between hfrac and lratio'
    print '              [e.g. where the hfrac differences are? or maybe hfrac averaged over the top N annotations?]) i.e. find what kinds of clones hfrac and lratio disagree on'
    print '    TODO test on simulation samples that are *hard*, i.e. that all have the same VJ and cdr3 length'
    print '    TODO hfrac thresholds should maybe depend on how much of which regions (v/d/j) we have'
    print '    TODO add progress info for viterbi'
    print '    TODO add emissions rescaling to bcrham scons test'
    print '    TODO work out what to do with regional total scores for per-gene support'

# ----------------------------------------------------------------------------------------
rows, columns = [int(v) for v in check_output(['stty', 'size']).split()]  # get actual tty height and width
formatter_class = lambda prog: argparse.HelpFormatter(prog, max_help_position=columns, width=columns)
parser = argparse.ArgumentParser(formatter_class=formatter_class)
subparsers = parser.add_subparsers(dest='action')

parent_parser = argparse.ArgumentParser(add_help=False)
parent_parser.add_argument('--debug', type=int, default=0, choices=[0, 1, 2], help='Debug verbosity level.')
parent_parser.add_argument('--sw-debug', type=int, choices=[0, 1, 2], help='Debug level for Smith-Waterman.')
parent_parser.add_argument('--no-clean', action='store_true', help='Don\'t remove the various temp files')
parent_parser.add_argument('--is-data', action='store_true', help='deprecated! use --is-simu for simulation')
parent_parser.add_argument('--is-simu', action='store_true', help='Set if running on simulated sequences')
parent_parser.add_argument('--skip-unproductive', action='store_true', help='Skip sequences which Smith-Waterman determines to be unproductive (they have stop codons, are out of frame, etc.)')
parent_parser.add_argument('--seed', type=int, default=int(time.time()), help='Random seed for use (mostly) by recombinator (to allow reproducibility)')
parent_parser.add_argument('--no-indels', action='store_true', help='Skip smith-waterman matches that include indels. Note that this just *skips* them, you probably also want to increase the gap-open penalty to prevent vdjalign from finding them in the first place.')
parent_parser.add_argument('--no-random-divvy', action='store_true', help='Don\'t shuffle the order of the input sequences before passing on to ham')  # it's imperative to shuffle if you're partitioning on simulation, or if you're partitioning with more than one process. But it may also be kinda slow.
parent_parser.add_argument('--only-csv-plots', action='store_true', help='only write csv plots')
parent_parser.add_argument('--seqfile', help='input sequence file')
parent_parser.add_argument('--name-column', default='unique_id', help='csv column name for sequence ids')
parent_parser.add_argument('--seq-column', default='seq', help='csv column name for nucleotide sequences')
parent_parser.add_argument('--parameter-dir', help='Directory to/from which to write/read sample-specific parameters. If not specified, we assume we should cache new parameters.')
parent_parser.add_argument('--parameter-type', default='hmm', choices=('sw', 'hmm'), help='Use parameters from Smith-Waterman (sw) or the HMM (hmm) subdirectories for inference/simulation?')
parent_parser.add_argument('--datadir', default=os.getcwd() + '/data/imgt', help='Directory from which to read non-sample-specific information (e.g. germline genes)')
parent_parser.add_argument('--alignment-dir', default=os.getcwd() + '/data/fam-alignments', help='Directory from which to read aligned germline sets. WILL BE REMOVED.')  # TODO remove this
parent_parser.add_argument('--outfname', help='Output file name.')
parent_parser.add_argument('--presto-output', action='store_true', help='write output file in presto format')
parent_parser.add_argument('--plotdir', help='Base directory to which to write plots (no plots are written if this isn\'t set)')
parent_parser.add_argument('--ighutil-dir', default=os.getenv('HOME') + '/.local', help='Path to vdjalign executable. The default (%(default)s) is where \'pip install --user\' typically puts things')
parent_parser.add_argument('--workdir', help='Temporary working directory (see also <no-clean>)')
parent_parser.add_argument('--persistent-cachefname', help='Name of file which will be used as an initial cache file (if it exists), and to which all cached info will be written out before exiting.')
parent_parser.add_argument('--abbreviate', action='store_true', help='Abbreviate/translate sequence ids to improve readability of partition debug output. Uses a, b, c, ..., aa, ab, ...')
parent_parser.add_argument('--n-procs', default='1', help='Number of processes over which to parallelize (Can be colon-separated list: first number is procs for hmm, second (should be smaller) is procs for smith-waterman)')
parent_parser.add_argument('--n-max-procs', default=250, help='Never allow more processes than this (default %(default)d)')
parent_parser.add_argument('--slurm', action='store_true', help='Run multiple processes with slurm, otherwise just runs them on local machine. NOTE make sure to set <workdir> to something visible on all batch nodes.')
parent_parser.add_argument('--queries', help='Colon-separated list of query names to which we restrict ourselves')
parent_parser.add_argument('--reco-ids', help='Colon-separated list of rearrangement-event IDs to which we restrict ourselves')  # or recombination events
parent_parser.add_argument('--n-max-queries', type=int, default=-1, help='Maximum number of query sequences on which to run (except for simulator, where it\'s the number of rearrangement events)')
parent_parser.add_argument('--only-genes', help='Colon-separated list of genes to which to restrict the analysis')
parent_parser.add_argument('--n-max-per-region', default='3:5:2', help='Number of best smith-waterman matches (per region, in the format v:d:j) to pass on to the hmm')
parent_parser.add_argument('--default-v-fuzz', type=int, default=5, help='Size of the k space region over which to sum in the v direction')
parent_parser.add_argument('--default-d-fuzz', type=int, default=2, help='Size of the k space region over which to sum in the d direction')
parent_parser.add_argument('--gap-open-penalty', type=int, default=30, help='Penalty for indel creation in Smith-Waterman step.')
parent_parser.add_argument('--match-mismatch', default='5:1', help='match:mismatch scores for smith-waterman.')
parent_parser.add_argument('--max-logprob-drop', type=float, default=5., help='stop glomerating when the total logprob has dropped by this much')
parent_parser.add_argument('--apply-choice-probs-in-sw', action='store_true', help='Apply gene choice probs in Smith-Waterman step. Probably not a good idea (see comments in waterer.py).')
parent_parser.add_argument('--n-sets', type=int, default=1, help='Separate sequences into sets of size <n> before passing to hmm (i.e. \"k-hmm\").')
parent_parser.add_argument('--all-combinations', action='store_true', help='Run algorithm on *all* possible combinations of the input queries of length <n-sets> (otherwise, if <n-sets> is set, we run on sequential sets of <n-sets> in the input file).')
parent_parser.add_argument('--plot-performance', action='store_true', help='Write out plots comparing true and inferred distributions')
parent_parser.add_argument('--dont-rescale-emissions', action='store_true', help='Don\'t scale each hmm\'s emission probabilities to account for the branch length of each individual sequence.')
parent_parser.add_argument('--version', action='version', help='print version and exit', version='partis %s' % check_output(['git', 'tag']))
parent_parser.add_argument('--print-git-commit', action='store_true', help='print git commit hash')
parent_parser.add_argument('--smc-particles', type=int, default=1, help='DEPRECATED Number of particles (clustering paths) to simulate with SMC')
parent_parser.add_argument('--min-observations-to-write', type=int, default=20, help='For hmmwriter.py, if we see a gene version fewer times than this, we sum over other alleles, or other versions, etc. (see hmmwriter)')
# parent_parser.add_argument('--use_mean_at_boundaries', action='store_true', help='see note in hmmwriter')

subconfig = {
    'cache-parameters' : {'func' : run_partitiondriver, 'help' : 'Cache parameter values and write hmm model files.'},
    'run-viterbi'      : {'func' : run_partitiondriver, 'help' : 'Annotate (align) sequences in input file, i.e. run the viterbi algorithm, using pre-existing parameter directory.'},
    'partition'        : {'func' : run_partitiondriver, 'help' : 'Partition sequences in input file into clonally-related families using pre-existing parameter directory.'},
    'simulate'         : {'func' : run_simulation,      'help' : 'Generate simulated sequences based on information in pre-existing parameter directory.'},
    'run-forward'      : {'func' : run_partitiondriver, 'help' : 'Run the forward algorithm on sequences in input file, using pre-existing parameter directory. Not particularly useful except for debugging.'},
    'view-annotations' : {'func' : view_existing_output,'help' : 'Print (to std out) the annotations from an existing annotation output csv.'},
    'view-partitions'  : {'func' : view_existing_output,'help' : 'Print (to std out) the partitions from an existing partition output csv.'}
}

subargs = {subname : [] for subname in subconfig}

subargs['partition'].append({'name' : '--naive-hamming', 'kwargs' : {'action' : 'store_true', 'help' : 'agglomerate purely with naive hamming distance, i.e. set the low and high preclustering bounds to the same value'}})
subargs['partition'].append({'name' : '--naive-vsearch', 'kwargs' : {'action' : 'store_true', 'help' : 'Very fast clustering: infer naive (unmutated ancestor) for each input sequence, then toss it all into vsearch. But, of course, not as accurate as the slower methods.'}})
subargs['partition'].append({'name' : '--seed-unique-id', 'kwargs' : {'help' : 'Only look for sequences that are clonally related to this unique id. Much much much faster than partitioning the entire dataset.'}})
subargs['partition'].append({'name' : '--annotation-clustering', 'kwargs' : {'help' : 'Perform annotation-based clustering: group together sequences with the same V and J, same CDR3 length, and 90%% cdr identity. Very, very inaccurate.'}})
subargs['partition'].append({'name' : '--annotation-clustering-thresholds', 'kwargs' : {'default' : '0.9', 'help' : 'colon-separated list of thresholds for annotation-based (e.g. vollmers) clustering'}})
subargs['partition'].append({'name' : '--print-cluster-annotations', 'kwargs' : {'action' : 'store_true', 'help' : 'print annotation for each final cluster'}})
subargs['partition'].append({'name' : '--naive-hamming-bounds', 'kwargs' : {'help' : 'Clustering bounds (lo:hi colon-separated pair) on naive sequence hamming distance. If not specified, the bounds are set based on the per-dataset mutation levels. For most purposes should be left at the defaults.'}})
subargs['partition'].append({'name' : '--logprob-ratio-threshold', 'kwargs' : {'type' : float, 'default' : 18., 'help' : 'reaches a min value of <this> minus five for large clusters.'}})
subargs['partition'].append({'name' : '--synthetic-distance-based-partition', 'kwargs' : {'action' : 'store_true', 'help' : 'Use simulation truth info to create a synthetic distance-based partition (for validation).'}})
subargs['partition'].append({'name' : '--cache-naive-hfracs', 'kwargs' : {'action' : 'store_true', 'help' : 'In addition to naive sequences and log probabilities, also cache naive hamming fractions between cluster pairs. Only really useful for plotting or testing.'}})
subargs['partition'].append({'name' : '--n-precache-procs', 'kwargs' : {'type' : int, 'help' : 'Number of processes to use when precaching naive sequences. Default is set based on some heuristics, and should typically only be overridden for testing.'}})
subargs['partition'].append({'name' : '--biggest-naive-seq-cluster-to-calculate', 'kwargs' : {'type' : int, 'default' : 7, 'help' : 'start thinking about subsampling before you calculate anything if cluster is bigger than this'}})
subargs['partition'].append({'name' : '--biggest-logprob-cluster-to-calculate', 'kwargs' : {'type' : int, 'default' : 7, 'help' : 'start thinking about subsampling before you calculate anything if cluster is bigger than this'}})
subargs['partition'].append({'name' : '--n-partitions-to-write', 'kwargs' : {'type' : int, 'default' : 5, 'help' : 'Number of partitions (surrounding the best partition) to write to output file.'}})
subargs['partition'].append({'name' : '--naive-swarm', 'kwargs' : {'action' : 'store_true', 'help' : 'Use swarm instead of vsearch, which the developer recommends. Didn\'t seem to help much, and needs more work to optimize threshold, so DO NOT USE.'}})

subargs['simulate'].append({'name' : '--mutation-multiplier', 'kwargs' : {'type' : float, 'help' : 'Multiply observed branch lengths by some factor when simulating, e.g. if in data it was 0.05, but you want closer to ten percent in your simulation, set this to 2'}})
subargs['simulate'].append({'name' : '--mimic-data-read-length', 'kwargs' : {'action' : 'store_true', 'help' : 'trim V 5\' and D 3\' to mimic read lengths seen in data'}})
subargs['simulate'].append({'name' : '--n-sim-events', 'kwargs' : {'type' : int, 'default' : 1, 'help' : 'Number of rearrangement events to simulate'}})
subargs['simulate'].append({'name' : '--n-trees', 'kwargs' : {'type' : int, 'default' : 500, 'help' : 'Number of phylogenetic trees from which to choose during simulation (we pre-generate this many trees before starting a simulation run, then for each rearrangement event choose one at random -- so this should be at least of order the number of simulated events, so your clonal families don\'t all have the same tree).'}})
subargs['simulate'].append({'name' : '--n-leaves', 'kwargs' : {'type' : float, 'default' : 5., 'help' : 'Parameter describing the number of leaves per tree (maybe the mean, maybe not -- depends on the distribution)'}})
subargs['simulate'].append({'name' : '--constant-number-of-leaves', 'kwargs' : {'action' : 'store_true', 'help' : 'Give all trees the same number of leaves'}})
subargs['simulate'].append({'name' : '--n-leaf-distribution', 'kwargs' : {'default' : 'geometric', 'choices' : ['geometric', 'box', 'zipf'], 'help' : 'distribution from which to draw the number of leaves for each tree'}})
subargs['simulate'].append({'name' : '--indel-frequency', 'kwargs' : {'default' : 0., 'type' : float, 'help' : 'fraction of simulated sequences with indels'}})
# disabled for now, but if you want multiple indels per sequence you can use this (you'd also need to uncomment a line in recombinator):)
#subargs['simulate'].append({'name' : '--mean-n-indels', 'kwargs' : {'default' : 1, 'type' : int, 'help' : 'mean number of indels in each sequence which we\'ve already decided has indels (geometric distribution)'}})
subargs['simulate'].append({'name' : '--mean-indel-length', 'kwargs' : {'default' : 5, 'help' : 'mean length of each indel (geometric distribution)'}})
subargs['simulate'].append({'name' : '--indel-location', 'kwargs' : {'choices' : [None, 'v', 'cdr3'], 'help' : 'where to put the indels'}})
subargs['simulate'].append({'name' : '--uniform-vj-choice-probs', 'kwargs' : {'action' : 'store_true', 'help' : 'In simulation, give all possible combinations of allowed v and j germline genes the same probability'}})
# NOTE command to generate gtr parameter file: [stoat] partis/ > zcat /shared/silo_researcher/Matsen_F/MatsenGrp/data/bcr/output_sw/A/04-A-M_gtr_tr-qi-gi.json.gz | jq .independentParameters | grep -v '[{}]' | sed 's/["\:,]//g' | sed 's/^[ ][ ]*//' | sed 's/ /,/' | sort >data/gtr.txt)
subargs['simulate'].append({'name' : '--gtrfname', 'kwargs' : {'default' : 'data/recombinator/gtr.txt', 'help' : 'File with list of GTR parameters. Fed into bppseqgen along with the chosen tree. Corresponds to an arbitrary dataset at the moment, but eventually will be inferred per-dataset.'}})

subparsermap = {}
for name, vals in subconfig.items():
    subparsermap[name] = subparsers.add_parser(name, parents=[parent_parser], help=vals['help'], formatter_class=formatter_class)
    subparsermap[name].set_defaults(func=vals['func'])
    for argconf in subargs[name]:
        subparsermap[name].add_argument(argconf['name'], **argconf['kwargs'])

# ----------------------------------------------------------------------------------------
if '--action' in sys.argv:
    print '  NOTE we\'ve switched --action to a positional argument, so you can remove \'--action\' from your command line'
    sys.argv.remove('--action')

args = parser.parse_args()

# add OR of all arguments to all subparsers to <args>, as None (to avoid having to rewrite a *##!(%ton of other code)
for name in subconfig:
    for argconf in subargs[name]:
        if argconf['name'][:2] != '--':
            raise Exception('expected argument %s to be of form --<stuff>' % argconf['name'])
        argname = argconf['name'][2:].replace('-', '_')
        if argname not in args.__dict__:
            args.__dict__[argname] = None

args.only_genes = utils.get_arg_list(args.only_genes)
args.n_procs = utils.get_arg_list(args.n_procs, intify=True)
args.n_fewer_procs = args.n_procs[0] if len(args.n_procs) == 1 else args.n_procs[1]
args.n_procs = args.n_procs[0]

# if n_procs < 1 or n_procs > 9999:  # It happened, at least once. You know, probably.
#     raise Exception('bad n_procs %s' % n_procs)
if args.n_procs > args.n_max_procs:
    print 'reducing n procs %d to --n-max-procs %d' % (args.n_procs, args.n_max_procs)
    args.n_procs = args.n_max_procs
if args.n_fewer_procs > args.n_max_procs:
    print 'reducing n procs %d to --n-max-procs %d' % (args.n_fewer_procs, args.n_max_procs)
    args.n_fewer_procs = args.n_max_procs

if args.print_git_commit:
    print 'RUN ' + ' '.join(sys.argv)
    print '    git commit %s   (tag %s)' % (check_output(['git', 'rev-parse', 'HEAD']).strip(), check_output(['git', 'tag']).strip())

if args.is_data:  # if <is_data> was set on the command line, print a warning and continue
    print '  NOTE --is-data is no longer needed (it\'s the default; add --is-simu if running on simulation)'
    if args.is_simu:
        raise Exception('--is-data and --is-simu both set on the command line')
elif args.is_simu:
    pass  # args.is_data = False
else:  # if neither was given on the command line, set is_data to True
    args.is_data = True

if args.slurm and '/tmp' in args.workdir:
    raise Exception('it appears that <workdir> isn\'t set to something visible to all slurm nodes')

if args.smc_particles != 1:
    raise Exception('sequential monte carlo is not, at this juncture, supported.')

if args.no_indels and args.gap_open_penalty < 1000:
    print 'forcing --gap-open-penalty to 1000 to prevent indels, since --no-indels was specified (you can also adjust this penalty directly)'
    args.gap_open_penalty = 1000

if args.workdir is None:  # set default here so we know whether it was set by hand or not
    args.workdir = '/tmp/' + os.path.basename(os.getenv('HOME')) + '/hmms/' + str(random.randint(0, 999999))
if os.path.exists(args.workdir):
    raise Exception('workdir %s already exists' % args.workdir)

if args.plot_performance:
    if args.plotdir is None:
        raise Exception('can\'t plot performance unless --plotdir is specified')
    if not args.is_simu:
        raise Exception('can\'t plot performance unless --is-simu is set')

# ----------------------------------------------------------------------------------------
random.seed(args.seed)
start = time.time()
args.func(args)
print '      total time: %.1f' % (time.time()-start)
